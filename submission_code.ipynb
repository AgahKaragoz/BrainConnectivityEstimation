{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f586</th>\n",
       "      <th>f587</th>\n",
       "      <th>f588</th>\n",
       "      <th>f589</th>\n",
       "      <th>f590</th>\n",
       "      <th>f591</th>\n",
       "      <th>f592</th>\n",
       "      <th>f593</th>\n",
       "      <th>f594</th>\n",
       "      <th>f595</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122661</td>\n",
       "      <td>0.109112</td>\n",
       "      <td>0.231773</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122661</td>\n",
       "      <td>0.109112</td>\n",
       "      <td>0.092518</td>\n",
       "      <td>0.215179</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.092518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083222</td>\n",
       "      <td>0.155292</td>\n",
       "      <td>0.176474</td>\n",
       "      <td>0.163567</td>\n",
       "      <td>0.098551</td>\n",
       "      <td>0.085389</td>\n",
       "      <td>0.086820</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.211176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045889</td>\n",
       "      <td>0.077398</td>\n",
       "      <td>0.031509</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045889</td>\n",
       "      <td>0.077398</td>\n",
       "      <td>0.181591</td>\n",
       "      <td>0.135702</td>\n",
       "      <td>0.104193</td>\n",
       "      <td>0.181591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087444</td>\n",
       "      <td>0.107125</td>\n",
       "      <td>0.168047</td>\n",
       "      <td>0.123742</td>\n",
       "      <td>0.098362</td>\n",
       "      <td>0.105015</td>\n",
       "      <td>0.099260</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.180088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.046635</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.114418</td>\n",
       "      <td>0.134456</td>\n",
       "      <td>0.087822</td>\n",
       "      <td>0.114418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189319</td>\n",
       "      <td>0.125778</td>\n",
       "      <td>0.253501</td>\n",
       "      <td>0.186712</td>\n",
       "      <td>0.242613</td>\n",
       "      <td>0.193321</td>\n",
       "      <td>0.157509</td>\n",
       "      <td>0.090372</td>\n",
       "      <td>0.090372</td>\n",
       "      <td>0.326458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>0.097044</td>\n",
       "      <td>0.039774</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072407</td>\n",
       "      <td>0.051349</td>\n",
       "      <td>0.140081</td>\n",
       "      <td>0.098872</td>\n",
       "      <td>0.092207</td>\n",
       "      <td>0.122251</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.234741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007235</td>\n",
       "      <td>0.048022</td>\n",
       "      <td>0.040787</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>0.048022</td>\n",
       "      <td>0.135871</td>\n",
       "      <td>0.128635</td>\n",
       "      <td>0.087848</td>\n",
       "      <td>0.135871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057658</td>\n",
       "      <td>0.070526</td>\n",
       "      <td>0.123818</td>\n",
       "      <td>0.139617</td>\n",
       "      <td>0.132032</td>\n",
       "      <td>0.120361</td>\n",
       "      <td>0.061331</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.213473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>0.114168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>0.121323</td>\n",
       "      <td>0.140506</td>\n",
       "      <td>0.026339</td>\n",
       "      <td>0.121323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094795</td>\n",
       "      <td>0.127945</td>\n",
       "      <td>0.237968</td>\n",
       "      <td>0.119351</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.104275</td>\n",
       "      <td>0.091191</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>0.218438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.106997</td>\n",
       "      <td>0.157994</td>\n",
       "      <td>0.050997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106997</td>\n",
       "      <td>0.157994</td>\n",
       "      <td>0.117481</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.040513</td>\n",
       "      <td>0.117481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137664</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.229986</td>\n",
       "      <td>0.131211</td>\n",
       "      <td>0.168520</td>\n",
       "      <td>0.157771</td>\n",
       "      <td>0.042123</td>\n",
       "      <td>0.042123</td>\n",
       "      <td>0.332688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.023589</td>\n",
       "      <td>0.017617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.023589</td>\n",
       "      <td>0.178104</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.154515</td>\n",
       "      <td>0.178104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076848</td>\n",
       "      <td>0.048370</td>\n",
       "      <td>0.222110</td>\n",
       "      <td>0.157774</td>\n",
       "      <td>0.158509</td>\n",
       "      <td>0.135718</td>\n",
       "      <td>0.123088</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>0.303554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.081350</td>\n",
       "      <td>0.067428</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081350</td>\n",
       "      <td>0.067428</td>\n",
       "      <td>0.128558</td>\n",
       "      <td>0.047208</td>\n",
       "      <td>0.061129</td>\n",
       "      <td>0.128558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093422</td>\n",
       "      <td>0.115975</td>\n",
       "      <td>0.139737</td>\n",
       "      <td>0.137801</td>\n",
       "      <td>0.083554</td>\n",
       "      <td>0.097807</td>\n",
       "      <td>0.115830</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.204185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.053963</td>\n",
       "      <td>0.107713</td>\n",
       "      <td>0.161676</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053963</td>\n",
       "      <td>0.107713</td>\n",
       "      <td>0.110151</td>\n",
       "      <td>0.164114</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.110151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184799</td>\n",
       "      <td>0.018664</td>\n",
       "      <td>0.176090</td>\n",
       "      <td>0.187941</td>\n",
       "      <td>0.119456</td>\n",
       "      <td>0.169442</td>\n",
       "      <td>0.177676</td>\n",
       "      <td>0.062520</td>\n",
       "      <td>0.062520</td>\n",
       "      <td>0.328674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 595 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2        f3  f4        f5        f6        f7        f8  \\\n",
       "0  0.122661  0.109112  0.231773   0  0.122661  0.109112  0.092518  0.215179   \n",
       "1  0.045889  0.077398  0.031509   0  0.045889  0.077398  0.181591  0.135702   \n",
       "2  0.020038  0.026596  0.046635   0  0.020038  0.026596  0.114418  0.134456   \n",
       "3  0.015838  0.073108  0.057270   0  0.015838  0.073108  0.112882  0.097044   \n",
       "4  0.007235  0.048022  0.040787   0  0.007235  0.048022  0.135871  0.128635   \n",
       "5  0.019183  0.094985  0.114168   0  0.019183  0.094985  0.121323  0.140506   \n",
       "6  0.106997  0.157994  0.050997   0  0.106997  0.157994  0.117481  0.010484   \n",
       "7  0.005972  0.023589  0.017617   0  0.005972  0.023589  0.178104  0.172131   \n",
       "8  0.081350  0.067428  0.013921   0  0.081350  0.067428  0.128558  0.047208   \n",
       "9  0.053963  0.107713  0.161676   0  0.053963  0.107713  0.110151  0.164114   \n",
       "\n",
       "         f9       f10  ...      f586      f587      f588      f589      f590  \\\n",
       "0  0.016593  0.092518  ...  0.083222  0.155292  0.176474  0.163567  0.098551   \n",
       "1  0.104193  0.181591  ...  0.087444  0.107125  0.168047  0.123742  0.098362   \n",
       "2  0.087822  0.114418  ...  0.189319  0.125778  0.253501  0.186712  0.242613   \n",
       "3  0.039774  0.112882  ...  0.072407  0.051349  0.140081  0.098872  0.092207   \n",
       "4  0.087848  0.135871  ...  0.057658  0.070526  0.123818  0.139617  0.132032   \n",
       "5  0.026339  0.121323  ...  0.094795  0.127945  0.237968  0.119351  0.115340   \n",
       "6  0.040513  0.117481  ...  0.137664  0.026861  0.313305  0.229986  0.131211   \n",
       "7  0.154515  0.178104  ...  0.076848  0.048370  0.222110  0.157774  0.158509   \n",
       "8  0.061129  0.128558  ...  0.093422  0.115975  0.139737  0.137801  0.083554   \n",
       "9  0.002438  0.110151  ...  0.184799  0.018664  0.176090  0.187941  0.119456   \n",
       "\n",
       "       f591      f592      f593      f594      f595  \n",
       "0  0.085389  0.086820  0.004597  0.004597  0.211176  \n",
       "1  0.105015  0.099260  0.002731  0.002731  0.180088  \n",
       "2  0.193321  0.157509  0.090372  0.090372  0.326458  \n",
       "3  0.122251  0.062600  0.002926  0.002926  0.234741  \n",
       "4  0.120361  0.061331  0.002288  0.002288  0.213473  \n",
       "5  0.104275  0.091191  0.009266  0.009266  0.218438  \n",
       "6  0.168520  0.157771  0.042123  0.042123  0.332688  \n",
       "7  0.135718  0.123088  0.022291  0.022291  0.303554  \n",
       "8  0.097807  0.115830  0.001051  0.001051  0.204185  \n",
       "9  0.169442  0.177676  0.062520  0.062520  0.328674  \n",
       "\n",
       "[10 rows x 595 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSubmission = pd.read_csv('./data/sampleSubmission.csv')\n",
    "allTrainingDataT0 = pd.read_csv('./data/train_t0.csv')\n",
    "allTrainingDataT0 = allTrainingDataT0.loc[:, 'f1':'f595']\n",
    "allTrainingDataT1 = pd.read_csv('./data/train_t1.csv')\n",
    "allTrainingDataT1 = allTrainingDataT1.loc[:, 'f1':'f595']\n",
    "finalTestingDataT0 = pd.read_csv('./data/test_t0.csv') #Do not touch it\n",
    "finalTestingDataT0 = finalTestingDataT0.loc[:, 'f1':'f595']\n",
    "finalTestingDataT0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 595)\n"
     ]
    }
   ],
   "source": [
    "#Remove outliers by mean method \n",
    "np.warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "threshold= 2 #Work best at 2\n",
    "mean_outliered_allTrainingDataT0 = allTrainingDataT0\n",
    "mean_outliered_allTrainingDataT1 = allTrainingDataT1\n",
    "for i in range(len(mean_outliered_allTrainingDataT0.loc[0,:])):\n",
    "    feature = \"f\"+str(i+1)\n",
    "    meanT0 = mean_outliered_allTrainingDataT0[feature].to_numpy().mean()\n",
    "    meanT1 = mean_outliered_allTrainingDataT1[feature].to_numpy().mean()\n",
    "    zT0=np.abs(stats.zscore(mean_outliered_allTrainingDataT0[feature]))\n",
    "    for j in range(len(np.where(zT0>threshold)[0])):\n",
    "        mean_outliered_allTrainingDataT0.loc[np.where(zT0>threshold)[0][j],[feature]] = meanT0\n",
    "    zT1=np.abs(stats.zscore(mean_outliered_allTrainingDataT1[feature]))\n",
    "    for j in range(len(np.where(zT1>threshold)[0])):\n",
    "        mean_outliered_allTrainingDataT1.loc[np.where(zT1>threshold)[0][j],[feature]] = meanT1\n",
    "        \n",
    "\n",
    "print(mean_outliered_allTrainingDataT0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 595)\n"
     ]
    }
   ],
   "source": [
    "#Remove outliers by neighbour method\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "threshold=3\n",
    "neighbour_outliered_allTrainingDataT0 = allTrainingDataT0\n",
    "neighbour_outliered_allTrainingDataT1 = allTrainingDataT1\n",
    "for i in range(len(neighbour_outliered_allTrainingDataT0)):\n",
    "    feature = \"f\"+str(i+1)\n",
    "    zT0=np.abs(stats.zscore(neighbour_outliered_allTrainingDataT0[feature]))\n",
    "    for j in range(len(np.where(zT0>threshold)[0])):\n",
    "        if(np.where(zT0>threshold)[0][j] == 149):\n",
    "            next_index = np.where(zT0>threshold)[0][j]-2\n",
    "            previous_index = np.where(zT0>threshold)[0][j]-1\n",
    "        elif(np.where(zT0>threshold)[0][j] == 0):\n",
    "            next_index = np.where(zT0>threshold)[0][j]+1\n",
    "            previous_index = np.where(zT0>threshold)[0][j]+2\n",
    "        else:\n",
    "            next_index = np.where(zT0>threshold)[0][j]+1\n",
    "            previous_index = np.where(zT0>threshold)[0][j]-1\n",
    "            \n",
    "        neighbour_outliered_allTrainingDataT0.loc[np.where(zT0>threshold)[0][j],[feature]] = (neighbour_outliered_allTrainingDataT0.loc[next_index,[feature]] + neighbour_outliered_allTrainingDataT0.loc[previous_index,[feature]])/2\n",
    "\n",
    "    zT1=np.abs(stats.zscore(neighbour_outliered_allTrainingDataT1[feature]))\n",
    "    for j in range(len(np.where(zT1>threshold)[0])):\n",
    "        if(np.where(zT1>threshold)[0][j] == 149):\n",
    "            next_index = np.where(zT1>threshold)[0][j]-2\n",
    "            previous_index = np.where(zT1>threshold)[0][j]-1\n",
    "        elif(np.where(zT1>threshold)[0][j] == 0):\n",
    "            next_index = np.where(zT1>threshold)[0][j]+1\n",
    "            previous_index = np.where(zT1>threshold)[0][j]+2\n",
    "        else:\n",
    "            next_index = np.where(zT1>threshold)[0][j]+1\n",
    "            previous_index = np.where(zT1>threshold)[0][j]-1\n",
    "        neighbour_outliered_allTrainingDataT1.loc[np.where(zT1>threshold)[0][j],[feature]] = (neighbour_outliered_allTrainingDataT1.loc[next_index,[feature]] + neighbour_outliered_allTrainingDataT1.loc[previous_index,[feature]])/2\n",
    "        \n",
    "\n",
    "print(neighbour_outliered_allTrainingDataT0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Scale the data ----- Not worked well\\nnormalized_changedDataT0 = (changedDataT0-changedDataT0.mean())/changedDataT0.std()\\nnormalized_changedDataT1 = (changedDataT1-changedDataT1.mean())/changedDataT1.std()\\n\\n\\nnormalized_changedDataT0 = pd.DataFrame(np.nan_to_num(normalized_changedDataT0))\\nnormalized_changedDataT1 = pd.DataFrame(np.nan_to_num(normalized_changedDataT1))\\nprint(\"DONE\")\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Scale the data ----- Not worked well\n",
    "normalized_changedDataT0 = (changedDataT0-changedDataT0.mean())/changedDataT0.std()\n",
    "normalized_changedDataT1 = (changedDataT1-changedDataT1.mean())/changedDataT1.std()\n",
    "\n",
    "\n",
    "normalized_changedDataT0 = pd.DataFrame(np.nan_to_num(normalized_changedDataT0))\n",
    "normalized_changedDataT1 = pd.DataFrame(np.nan_to_num(normalized_changedDataT1))\n",
    "print(\"DONE\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CV Fold 1 : Mean Squared Error -> 0.00240\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CV Fold 2 : Mean Squared Error -> 0.00191\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CV Fold 3 : Mean Squared Error -> 0.00230\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CV Fold 4 : Mean Squared Error -> 0.00214\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CV Fold 5 : Mean Squared Error -> 0.00225\n",
      "\n",
      "Average Error => 0.00220\n"
     ]
    }
   ],
   "source": [
    "#5 Fold Cross Validation\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "numberOfFolds = 5\n",
    "kf = KFold(n_splits=numberOfFolds, shuffle=True) \n",
    "split_indices = kf.split(range(allTrainingDataT0.shape[0]))\n",
    "\n",
    "regr = MultiOutputRegressor(SVR(kernel='rbf', C=1000, gamma=.1, epsilon=.01))\n",
    "allFoldsErrors = []\n",
    "cv_index = 1\n",
    "for train_indices, test_indices in split_indices:\n",
    "    X = allTrainingDataT0.loc[train_indices, :]\n",
    "    Y = allTrainingDataT1.loc[train_indices, :]\n",
    "    \n",
    "    regr.fit(X, Y)\n",
    "    prediction = regr.predict(allTrainingDataT0.loc[test_indices, :])\n",
    "    meanSquaredError = mse(allTrainingDataT1.loc[test_indices, :].to_numpy().flatten(), prediction.flatten())\n",
    "    print(\"\\n\\n\\nCV Fold {} : Mean Squared Error -> {:.5f}\\n\".format(cv_index, meanSquaredError))\n",
    "    allFoldsErrors.append(meanSquaredError)\n",
    "    cv_index += 1\n",
    "   \n",
    "    \"\"\"\n",
    "    PRINT Indicies and Data\n",
    "    \n",
    "    print(\"\\nThese are train indicies: {}\".format(train_indices))\n",
    "    print(\"\\nThis is training data:\\n {}\\n\\n\".format(allTainingDataT0.loc[train_indices, :]))\n",
    "    print(\"\\nThese are test indices: {}\".format(test_indices))\n",
    "    print(\"\\nThis is testing data:\\n {}\\n\\n\".format(allTainingDataT0.loc[test_indices, :]))\n",
    "    \"\"\"\n",
    "    \n",
    "print(\"Average Error => {:.5f}\".format(sum(allFoldsErrors) / numberOfFolds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "regr.fit(mean_outliered_allTrainingDataT0, mean_outliered_allTrainingDataT1)\n",
    "prediction = regr.predict(finalTestingDataT0)\n",
    "predictionFlattened = prediction.flatten()\n",
    "\n",
    "submission = [[\"ID\",\"predicted\"]]\n",
    "for i in range(47600):\n",
    "    submission.append([i, predictionFlattened[i]])\n",
    "\n",
    "submissionDF = pd.DataFrame(submission)\n",
    "submissionDF.to_csv('submission.csv', index=False, header=False)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.103964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.145209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.027712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  predicted\n",
       "0   0   0.027712\n",
       "1   1   0.103964\n",
       "2   2   0.145209\n",
       "3   3   0.000000\n",
       "4   4   0.027712"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readSubmission = pd.read_csv('./submission.csv')\n",
    "readSubmission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
